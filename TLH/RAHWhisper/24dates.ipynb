{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import seed_everything, parse_date_with_prompt, generate_random_date, read_file\n",
    "from dataset_text import TextDataset, TextTokenizer\n",
    "from train_text import TextTransformer\n",
    "seed_everything(42)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "import csv\n",
    "## IF not backend is detected\n",
    "# import torchaudio\n",
    "\n",
    "# # Check the current backend\n",
    "# torchaudio.set_audio_backend(\"soundfile\")\n",
    "# torchaudio.list_audio_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Syntetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo sintetico esta creado de forma sencilla  basandome en los tipos de prompts de training y test.\n",
    "Lo mas dificil de ver es si las fechas tipo proximo viernes, martes, etc. son correctas de forma manual una visualizacion sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/01/25\n",
      "07/01/25\n",
      "11/01/25\n"
     ]
    }
   ],
   "source": [
    "# A dia 4 de enero de 2025 (sabado)\n",
    "print(parse_date_with_prompt(\"04/01/25 el proximo viernes\")) # 10/01/25\n",
    "print(parse_date_with_prompt(\"04/01/25 el proximo martes\")) # 07/01/25\n",
    "print(parse_date_with_prompt(\"04/01/25 el proximo sábado\")) # 11/01/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(output_path, input_path=\"fechas1/fechas1_train.csv\"):\n",
    "    promt= []\n",
    "    syntetic_date = []\n",
    "    for date in read_file(input_path)[1]:\n",
    "        random_date=generate_random_date()\n",
    "        promt.append(f\"{random_date} {date}\")\n",
    "        syntetic_date.append(parse_date_with_prompt(promt[-1]))\n",
    "    print(f\"{promt[0]} -> {syntetic_date[0]}\")\n",
    "\n",
    "    with open(output_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Escribir los encabezados\n",
    "        writer.writerow([\"Instrucción\", \"Fecha Resultado\"])\n",
    "        # Escribir las filas de datos combinando las listas\n",
    "        for instruccion,fecha  in zip(promt, syntetic_date):\n",
    "            writer.writerow([instruccion, fecha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/05/57 por favor el siguiente jueves -> 17/05/57\n",
      "31/07/08 pasado mañana gracias -> 02/08/08\n"
     ]
    }
   ],
   "source": [
    "create_data(\"fechas1/fechas1_train_sintetic.csv\")\n",
    "create_data(\"fechas1/fechas1_test_sintetic.csv\", \"fechas1/fechas1_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TextTokenizer(\"fechas1/fechas1_train_sintetic.csv\")\n",
    "train_dataset = TextDataset(\"fechas1/fechas1_train_sintetic.csv\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gracias': 15,\n",
       " 'siguiente': 16,\n",
       " 'el': 17,\n",
       " 'viernes': 18,\n",
       " 'de': 19,\n",
       " 'por': 20,\n",
       " 'jueves': 21,\n",
       " 'tres': 22,\n",
       " 'este': 23,\n",
       " 'mañana': 24,\n",
       " 'martes': 25,\n",
       " 'favor': 26,\n",
       " 'en': 27,\n",
       " 'que': 28,\n",
       " 'lunes': 29,\n",
       " 'días': 30,\n",
       " 'próximo': 31,\n",
       " 'un': 32,\n",
       " 'pasado': 33,\n",
       " 'miércoles': 34,\n",
       " 'par': 35,\n",
       " 'viene': 36,\n",
       " '<unk>': 0,\n",
       " '<pad>': 1,\n",
       " '<sos>': 2,\n",
       " '<eos>': 3,\n",
       " '/': 4,\n",
       " '0': 5,\n",
       " '1': 6,\n",
       " '2': 7,\n",
       " '3': 8,\n",
       " '4': 9,\n",
       " '5': 10,\n",
       " '6': 11,\n",
       " '7': 12,\n",
       " '8': 13,\n",
       " '9': 14}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6,  8,  4,  5, 10,  4, 10, 12, 34, 29, 35, 32, 24,  3])\n",
      "13/05/57 por favor el siguiente jueves\n"
     ]
    }
   ],
   "source": [
    "a=\"13/05/57 por favor el siguiente jueves\"\n",
    "print(tokenizer.encode(a))\n",
    "print(tokenizer.decode(tokenizer.encode(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6,  8,  4,  5, 10,  4, 10, 12,  3])\n",
      "13/05/57\n"
     ]
    }
   ],
   "source": [
    "a=\"13/05/57\"\n",
    "print(tokenizer.encode(a))\n",
    "print(tokenizer.decode(tokenizer.encode(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TextTokenizer(\"fechas1/fechas1_train_sintetic.csv\")\n",
    "train_dataset = TextDataset(\"fechas1/fechas1_train_sintetic.csv\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 2,  6,  8,  4,  5, 10,  4, 10, 12, 34, 29, 35, 32, 24,  3,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1]), tensor([ 2,  6, 12,  4,  5, 10,  4, 10, 12,  3,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1]))\n",
      "13/05/57 por favor el siguiente jueves\n",
      "17/05/57\n",
      "13/05/57 por favor el siguiente jueves 17/05/57\n"
     ]
    }
   ],
   "source": [
    "data=train_dataset[0]\n",
    "print(data)\n",
    "print(tokenizer.decode(data[0]))\n",
    "print(tokenizer.decode(data[1]))\n",
    "print(train_dataset.promts[0], train_dataset.dates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/5: avg_loss: 0.18\n",
      "epoch 1/5: avg_loss: 0.09\n",
      "epoch 2/5: avg_loss: 0.08\n",
      "epoch 3/5: avg_loss: 0.07\n",
      "epoch 4/5: avg_loss: 0.07\n"
     ]
    }
   ],
   "source": [
    "model = TextTransformer(vocab_size=len(tokenizer.idx2word.keys()), d_model=256, nb_layers=4, \n",
    "                         d_ff=512, n_heads=8, d_head=32, dropout=0.1, seq_len=100)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "nb_epochs = 5\n",
    "batch_size = 16\n",
    "model.train()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "for e in range(nb_epochs):\n",
    "    avg_loss = 0\n",
    "    for x, y in trainloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss = model.loss(x, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avg_loss += loss.item()\n",
    "    print('epoch %d/%d: avg_loss: %.2f' % (e,nb_epochs,avg_loss/len(trainloader)))\n",
    "       \n",
    "torch.save([model, opt], 'model_24.pt')\n",
    "torch.save(tokenizer, 'tokenizer_24.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [model, opt] = torch.load('model_24.pt')\n",
    "# tokenizer = torch.load('tokenizer_24.pth')\n",
    "testset=TextDataset('fechas1/fechas1_test_sintetic.csv', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7 4 5 6 4 9 5\n",
      "7 7 4 5 6 4 9 5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x,y = testset[2]\n",
    "x = x.to(device)\n",
    "y_pred = model.generate(x[None,...])\n",
    "hyp = ' '.join([str(i) for i in y_pred[1:-1]])\n",
    "y = y.numpy().tolist()\n",
    "y = y[:y.index(3)]\n",
    "ref = ' '.join([str(i) for i in y[1:]])\n",
    "print(hyp)\n",
    "print(ref)\n",
    "print(editdistance.eval(hyp, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate 15.17%,  (1214/8000)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "err = 0\n",
    "num = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for i,(x, y) in enumerate(testset):    \n",
    "    x = x.to(device)    \n",
    "    y_pred = model.generate(x[None,...])\n",
    "    hyp = ' '.join([str(i) for i in y_pred[1:-1]])\n",
    "    # print('hyp', hyp)\n",
    "\n",
    "    y = y.numpy().tolist()\n",
    "    # find the first 3 <eos> in list y\n",
    "    y = y[:y.index(3)]\n",
    "    ref = ' '.join([str(i) for i in y[1:]])\n",
    "    # print('ref', ref)\n",
    "    # print('(%d/%d)' % (i, len(testset)) )\n",
    "    \n",
    "    # edit distance\n",
    "    err += editdistance.eval(hyp, ref)\n",
    "    num += len(ref.split())\n",
    "    \n",
    "print(f'error rate {err/num:.2%},  ({err}/{num})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rahwisper-qWUPAEuw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
