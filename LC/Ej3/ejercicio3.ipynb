{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Desarrollar y evaluar un Chunker utilizando el corpus ConLL2000 del NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "-------\n",
      "(S\n",
      "  (NP Rockwell/NNP International/NNP Corp./NNP)\n",
      "  (NP 's/POS Tulsa/NNP unit/NN)\n",
      "  (VP said/VBD)\n",
      "  (NP it/PRP)\n",
      "  (VP signed/VBD)\n",
      "  (NP a/DT tentative/JJ agreement/NN)\n",
      "  (VP extending/VBG)\n",
      "  (NP its/PRP$ contract/NN)\n",
      "  (PP with/IN)\n",
      "  (NP Boeing/NNP Co./NNP)\n",
      "  (VP to/TO provide/VB)\n",
      "  (NP structural/JJ parts/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP Boeing/NNP)\n",
      "  (NP 's/POS 747/CD jetliners/NNS)\n",
      "  ./.)\n",
      "[('Rockwell', 'NNP', 'B-NP'), ('International', 'NNP', 'I-NP'), ('Corp.', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('Tulsa', 'NNP', 'I-NP'), ('unit', 'NN', 'I-NP'), ('said', 'VBD', 'B-VP'), ('it', 'PRP', 'B-NP'), ('signed', 'VBD', 'B-VP'), ('a', 'DT', 'B-NP'), ('tentative', 'JJ', 'I-NP'), ('agreement', 'NN', 'I-NP'), ('extending', 'VBG', 'B-VP'), ('its', 'PRP$', 'B-NP'), ('contract', 'NN', 'I-NP'), ('with', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), ('Co.', 'NNP', 'I-NP'), ('to', 'TO', 'B-VP'), ('provide', 'VB', 'I-VP'), ('structural', 'JJ', 'B-NP'), ('parts', 'NNS', 'I-NP'), ('for', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), (\"'s\", 'POS', 'B-NP'), ('747', 'CD', 'I-NP'), ('jetliners', 'NNS', 'I-NP'), ('.', '.', 'O')]\n",
      "----\n",
      "[('NN', 'B-NP'), ('IN', 'B-PP'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'B-VP'), ('RB', 'I-VP'), ('VBN', 'I-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'B-PP'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'B-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n",
      "====\n",
      "[('NNP', 'B-NP'), ('NNP', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('NNP', 'I-NP'), ('NN', 'I-NP'), ('VBD', 'B-VP'), ('PRP', 'B-NP'), ('VBD', 'B-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('VBG', 'B-VP'), ('PRP$', 'B-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('NNP', 'I-NP'), ('TO', 'B-VP'), ('VB', 'I-VP'), ('JJ', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('POS', 'B-NP'), ('CD', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Importar y trabajar con el corpus conll2000\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "# nltk.download('conll2000')\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "conll_train = conll2000.chunked_sents(\"train.txt\")\n",
    "conll_test = conll2000.chunked_sents(\"test.txt\")\n",
    "print(conll_train[0])\n",
    "print(\"-------\")\n",
    "print(conll_test[0])\n",
    "\n",
    "import nltk.chunk\n",
    "\n",
    "train_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_train]\n",
    "test_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_test]\n",
    "print(test_chunks[0])\n",
    "\n",
    "\n",
    "train = [[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in train_chunks]\n",
    "test = [[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in test_chunks]\n",
    "print(\"----\")\n",
    "print(train[0])\n",
    "print(\"====\")\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import hmm\n",
    "from nltk.tag import tnt\n",
    "from conlleval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = hmm.HiddenMarkovModelTagger.train(train)\n",
    "tnt_model = tnt.TnT()\n",
    "tnt_model.train(train)\n",
    "u_chunker = nltk.tag.UnigramTagger(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_labels = [hmm_model.tag([t for (t, c) in test_sent]) for test_sent in test]\n",
    "tnt_labels = [tnt_model.tag([t for (t, c) in test_sent]) for test_sent in test]\n",
    "u_labels = [u_chunker.tag([t for (t, c) in test_sent]) for test_sent in test]\n",
    "true_labels = [[c for (t, c) in test_sent] for test_sent in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_true_labels = []\n",
    "for sent_labels in true_labels:\n",
    "    for label in sent_labels:\n",
    "        formated_true_labels.append(label)\n",
    "    formated_true_labels.append(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(predicted_labels):\n",
    "    pred_tags = []\n",
    "    for sent in predicted_labels:\n",
    "        for _, label in sent:\n",
    "            pred_tags.append(label)\n",
    "        pred_tags.append(\"O\")\n",
    "    return pred_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM\n",
      "processed 49389 tokens with 22758 phrases; found: 21891 phrases; correct: 19008.\n",
      "accuracy:  90.02%; (non-O)\n",
      "accuracy:  90.55%; precision:  86.83%; recall:  83.52%; FB1:  85.14\n",
      "               NP: precision:  86.45%; recall:  83.76%; FB1:  85.08  12422\n",
      "               PP: precision:  92.16%; recall:  83.50%; FB1:  87.62  4811\n",
      "               VP: precision:  82.33%; recall:  82.88%; FB1:  82.61  4658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86.83020419350417, 83.52227788030582, 85.14412416851442)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"HMM\")\n",
    "evaluate(parse_output(hmm_labels), formated_true_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TnT\n",
      "processed 49389 tokens with 22814 phrases; found: 21891 phrases; correct: 19112.\n",
      "accuracy:  89.35%; (non-O)\n",
      "accuracy:  89.98%; precision:  87.31%; recall:  83.77%; FB1:  85.50\n",
      "               NP: precision:  86.66%; recall:  84.03%; FB1:  85.32  12422\n",
      "               PP: precision:  92.45%; recall:  83.41%; FB1:  87.70  4811\n",
      "               VP: precision:  83.71%; recall:  83.49%; FB1:  83.60  4658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87.3052852770545, 83.77312176733585, 85.50274018566157)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TnT\")\n",
    "evaluate(parse_output(tnt_labels), formated_true_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "processed 49389 tokens with 25460 phrases; found: 21891 phrases; correct: 18909.\n",
      "accuracy:  76.15%; (non-O)\n",
      "accuracy:  78.78%; precision:  86.38%; recall:  74.27%; FB1:  79.87\n",
      "               NP: precision:  86.80%; recall:  79.87%; FB1:  83.19  12422\n",
      "               PP: precision:  97.07%; recall:  74.73%; FB1:  84.45  4811\n",
      "               VP: precision:  74.22%; recall:  60.53%; FB1:  66.68  4658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86.37796354666301, 74.26944226237235, 79.86737344512261)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unigram\")\n",
    "evaluate(parse_output(u_labels), formated_true_labels, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linguistica-computacional-D4IfWFXx-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
