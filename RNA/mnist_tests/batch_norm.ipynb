{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from main import MNIST_dataset, MNIST_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:  2.5.1+cu124\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version: \", torch.__version__)\n",
    "\n",
    "####################################################################\n",
    "# Set Device\n",
    "####################################################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MNIST  train  Dataset...\n",
      "\tTotal Len.:  60000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading MNIST  test  Dataset...\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 11\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "train_dataset = MNIST_dataset(partition=\"train\")\n",
    "test_dataset = MNIST_dataset(partition=\"test\")\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = multiprocessing.cpu_count() - 1\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "Params:  2919434\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Neural Network Class\n",
    "####################################################################\n",
    "\n",
    "\n",
    "# Creating our Neural Network - Fully Connected\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes=[[784, 1024], [1024, 1024], [1024, 1024], [1024, 10]],\n",
    "        criterion=None,\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(sizes) - 1):\n",
    "            dims = sizes[i]\n",
    "            self.layers.append(nn.Linear(dims[0], dims[1]))\n",
    "            self.layers.append(nn.BatchNorm1d(dims[1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        dims = sizes[-1]\n",
    "        self.classifier = nn.Linear(dims[0], dims[1])\n",
    "\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        if y != None:\n",
    "            loss = self.criterion(x, y)\n",
    "            return loss, x\n",
    "        return x\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = Net(\n",
    "    sizes=[[784, 1024], [1024, 1024], [1024, 1024], [1024, num_classes]],\n",
    "    criterion=criterion,\n",
    ")\n",
    "print(net)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(\"Params: \", count_parameters(net))\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9)\n",
    "epochs = 25\n",
    "\n",
    "trainer = MNIST_trainer(\n",
    "    net,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    epochs,\n",
    "    device,\n",
    "    model_path=\"models/batchnorm.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 600/600 [00:07<00:00, 85.16batch/s]\n",
      "Test 0: 100%|██████████| 100/100 [00:00<00:00, 145.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.001681 - Test Loss: 0.000838 - Train Accuracy: 94.90% - Test Accuracy: 97.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 600/600 [00:06<00:00, 89.37batch/s] \n",
      "Test 1: 100%|██████████| 100/100 [00:00<00:00, 119.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.000535 - Test Loss: 0.000657 - Train Accuracy: 98.33% - Test Accuracy: 97.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 600/600 [00:07<00:00, 83.57batch/s]\n",
      "Test 2: 100%|██████████| 100/100 [00:00<00:00, 111.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.000271 - Test Loss: 0.000592 - Train Accuracy: 99.15% - Test Accuracy: 98.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100%|██████████| 600/600 [00:07<00:00, 75.78batch/s]\n",
      "Test 3: 100%|██████████| 100/100 [00:00<00:00, 117.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.000164 - Test Loss: 0.000631 - Train Accuracy: 99.52% - Test Accuracy: 98.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100%|██████████| 600/600 [00:06<00:00, 86.65batch/s]\n",
      "Test 4: 100%|██████████| 100/100 [00:00<00:00, 104.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.000101 - Test Loss: 0.000598 - Train Accuracy: 99.71% - Test Accuracy: 98.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: 100%|██████████| 600/600 [00:06<00:00, 88.83batch/s]\n",
      "Test 5: 100%|██████████| 100/100 [00:00<00:00, 115.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.000073 - Test Loss: 0.000545 - Train Accuracy: 99.80% - Test Accuracy: 98.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100%|██████████| 600/600 [00:08<00:00, 71.39batch/s]\n",
      "Test 6: 100%|██████████| 100/100 [00:00<00:00, 110.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.000042 - Test Loss: 0.000546 - Train Accuracy: 99.92% - Test Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: 100%|██████████| 600/600 [00:07<00:00, 85.15batch/s]\n",
      "Test 7: 100%|██████████| 100/100 [00:01<00:00, 99.64batch/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.000041 - Test Loss: 0.000547 - Train Accuracy: 99.90% - Test Accuracy: 98.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100%|██████████| 600/600 [00:06<00:00, 93.70batch/s] \n",
      "Test 8: 100%|██████████| 100/100 [00:00<00:00, 119.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.000030 - Test Loss: 0.000588 - Train Accuracy: 99.93% - Test Accuracy: 98.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 600/600 [00:06<00:00, 90.65batch/s]\n",
      "Test 9: 100%|██████████| 100/100 [00:00<00:00, 108.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.000023 - Test Loss: 0.000572 - Train Accuracy: 99.95% - Test Accuracy: 98.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: 100%|██████████| 600/600 [00:06<00:00, 87.25batch/s]\n",
      "Test 10: 100%|██████████| 100/100 [00:00<00:00, 111.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.000017 - Test Loss: 0.000560 - Train Accuracy: 99.96% - Test Accuracy: 98.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: 100%|██████████| 600/600 [00:07<00:00, 80.42batch/s] \n",
      "Test 11: 100%|██████████| 100/100 [00:00<00:00, 115.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.000010 - Test Loss: 0.000516 - Train Accuracy: 99.99% - Test Accuracy: 98.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: 100%|██████████| 600/600 [00:06<00:00, 88.14batch/s]\n",
      "Test 12: 100%|██████████| 100/100 [00:00<00:00, 136.07batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.000014 - Test Loss: 0.000520 - Train Accuracy: 99.97% - Test Accuracy: 98.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: 100%|██████████| 600/600 [00:06<00:00, 88.55batch/s]\n",
      "Test 13: 100%|██████████| 100/100 [00:00<00:00, 116.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.000008 - Test Loss: 0.000529 - Train Accuracy: 99.99% - Test Accuracy: 98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: 100%|██████████| 600/600 [00:07<00:00, 82.26batch/s]\n",
      "Test 14: 100%|██████████| 100/100 [00:00<00:00, 118.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.000004 - Test Loss: 0.000531 - Train Accuracy: 100.00% - Test Accuracy: 98.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: 100%|██████████| 600/600 [00:07<00:00, 81.79batch/s]\n",
      "Test 15: 100%|██████████| 100/100 [00:00<00:00, 115.56batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.000005 - Test Loss: 0.000523 - Train Accuracy: 100.00% - Test Accuracy: 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: 100%|██████████| 600/600 [00:06<00:00, 90.25batch/s] \n",
      "Test 16: 100%|██████████| 100/100 [00:00<00:00, 119.22batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.000003 - Test Loss: 0.000520 - Train Accuracy: 100.00% - Test Accuracy: 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: 100%|██████████| 600/600 [00:06<00:00, 92.16batch/s]\n",
      "Test 17: 100%|██████████| 100/100 [00:00<00:00, 123.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.000003 - Test Loss: 0.000506 - Train Accuracy: 100.00% - Test Accuracy: 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: 100%|██████████| 600/600 [00:06<00:00, 91.23batch/s]\n",
      "Test 18: 100%|██████████| 100/100 [00:00<00:00, 114.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.000003 - Test Loss: 0.000543 - Train Accuracy: 100.00% - Test Accuracy: 98.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 600/600 [00:06<00:00, 90.54batch/s]\n",
      "Test 19: 100%|██████████| 100/100 [00:00<00:00, 124.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.000008 - Test Loss: 0.000531 - Train Accuracy: 99.98% - Test Accuracy: 98.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: 100%|██████████| 600/600 [00:06<00:00, 92.11batch/s]\n",
      "Test 20: 100%|██████████| 100/100 [00:01<00:00, 99.30batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 0.000011 - Test Loss: 0.000583 - Train Accuracy: 99.97% - Test Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: 100%|██████████| 600/600 [00:07<00:00, 83.02batch/s]\n",
      "Test 21: 100%|██████████| 100/100 [00:00<00:00, 110.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 0.000005 - Test Loss: 0.000547 - Train Accuracy: 100.00% - Test Accuracy: 98.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: 100%|██████████| 600/600 [00:07<00:00, 78.10batch/s]\n",
      "Test 22: 100%|██████████| 100/100 [00:01<00:00, 87.61batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 0.000007 - Test Loss: 0.000548 - Train Accuracy: 99.98% - Test Accuracy: 98.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: 100%|██████████| 600/600 [00:09<00:00, 64.95batch/s]\n",
      "Test 23: 100%|██████████| 100/100 [00:00<00:00, 101.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 0.000007 - Test Loss: 0.000584 - Train Accuracy: 99.98% - Test Accuracy: 98.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: 100%|██████████| 600/600 [00:07<00:00, 83.08batch/s]\n",
      "Test 24: 100%|██████████| 100/100 [00:00<00:00, 116.03batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 0.000003 - Test Loss: 0.000522 - Train Accuracy: 100.00% - Test Accuracy: 98.65%\n",
      "\n",
      "BEST TEST ACCURACY:  98.67  in epoch  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Training\n",
    "####################################################################\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/code/RNA/mnist_tests/main.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_loss += self.criterion(outputs, labels)\n",
      "Test 24: 100%|██████████| 100/100 [00:00<00:00, 101.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final best acc:  98.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Load best weights\n",
    "####################################################################\n",
    "\n",
    "trainer.get_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlps-yB44cTBw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
