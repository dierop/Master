{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "\n",
      "Loading CIFAR10  train  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  50000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading CIFAR10  test  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 11\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'CIFAR10_dataset1' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum workers\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_workers)\n\u001b[0;32m---> 94\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m####################################################################\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Neural Network Class\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m####################################################################\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Utilizamos ResnetBlock ahora\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlps-Z27HhEAS-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlps-Z27HhEAS-py3.10/lib/python3.10/site-packages/torch/utils/data/sampler.py:163\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/mlps-Z27HhEAS-py3.10/lib/python3.10/site-packages/torch/utils/data/sampler.py:172\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'CIFAR10_dataset1' has no len()"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as  F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Set Device\n",
    "####################################################################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "####################################################################\n",
    "# Dataset Class\n",
    "####################################################################\n",
    "\n",
    "\n",
    "\n",
    "#Agregaremos Ruido\n",
    "class AddGaussianNoise:\n",
    "    def _init_(self, mean=0.0, std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def _call_(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def _repr_(self):\n",
    "        return self._class.name_ + f\"(mean={self.mean}, std={self.std})\"\n",
    "\n",
    "#Quitamos las tecnicas agregadas y dejamos solo el noise\n",
    "da_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "da_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CIFAR10_dataset1(Dataset):\n",
    "\n",
    "    def __init__(self, transform, partition = \"train\"):\n",
    "\n",
    "        print(\"\\nLoading CIFAR10 \", partition, \" Dataset...\")\n",
    "        self.partition = partition\n",
    "        self.transform = transform\n",
    "        if self.partition == \"train\":\n",
    "            self.data = torchvision.datasets.CIFAR10('.data/',\n",
    "                                                     train=True,\n",
    "                                                     download=True)\n",
    "        else:\n",
    "            self.data = torchvision.datasets.CIFAR10('.data/',\n",
    "                                                     train=False,\n",
    "                                                     download=True)\n",
    "        print(\"\\tTotal Len.: \", len(self.data), \"\\n\", 50*\"-\")\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "\n",
    "        # Image\n",
    "        image = self.data[idx][0]\n",
    "        image_tensor = self.transform(image)\n",
    "\n",
    "        # Label\n",
    "        label = torch.tensor(self.data[idx][1])\n",
    "        label = F.one_hot(label, num_classes=10).float()\n",
    "\n",
    "        return {\"img\": image_tensor, \"label\": label}\n",
    "\n",
    "train_dataset = CIFAR10_dataset1(da_train, partition=\"train\")\n",
    "test_dataset = CIFAR10_dataset1(da_test, partition=\"test\")\n",
    "\n",
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "\n",
    "batch_size = 512\n",
    "num_workers = multiprocessing.cpu_count()-1\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "####################################################################\n",
    "# Neural Network Class\n",
    "####################################################################\n",
    "\n",
    "# Utilizamos ResnetBlock ahora\n",
    "class ResNetBlock(nn.Module):\n",
    "    def _init_(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self)._init_()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv_shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.conv_shortcut(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNetCNN(nn.Module):\n",
    "    def _init_(self, num_classes=10):\n",
    "        super(ResNetCNN, self)._init_()\n",
    "\n",
    "        self.resnet_layers = nn.Sequential(\n",
    "            ResNetBlock(3, 32, stride=1),\n",
    "            ResNetBlock(32, 32, stride=1),\n",
    "            ResNetBlock(32, 64, stride=2),\n",
    "            ResNetBlock(64, 64, stride=1),\n",
    "            ResNetBlock(64, 128, stride=2),\n",
    "            ResNetBlock(128, 128, stride=1),\n",
    "            ResNetBlock(128, 256, stride=2),\n",
    "            ResNetBlock(256, 256, stride=1),\n",
    "            ResNetBlock(256, 512, stride=2),\n",
    "            ResNetBlock(512, 512, stride=1)\n",
    "        )\n",
    "\n",
    "        # Calcula dinámicamente el tamaño de la salida\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 32, 32)  # Entrada ficticia (1, 3, 32, 32)\n",
    "            dummy_output = self.resnet_layers(dummy_input)\n",
    "            flattened_size = dummy_output.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_layers(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = ResNetCNN(\n",
    "    num_classes\n",
    "    )\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "epochs = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=0.01, steps_per_epoch=len(train_dataloader), epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Training\n",
    "####################################################################\n",
    "\n",
    "\n",
    "#Agregamos Early Stopping\n",
    "class EarlyStopping:\n",
    "    def _init_(self, patience=10, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def _call_(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "        elif val_loss > self.best_score - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "\n",
    "# Load model in GPU\n",
    "net.to(device)\n",
    "\n",
    "print(\"\\n---- Start Training ----\")\n",
    "early_stopping = EarlyStopping(patience=30, min_delta=0.001)\n",
    "best_accuracy = -1\n",
    "best_epoch = 0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    # TRAIN NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    with tqdm(iter(train_dataloader), desc=\"Epoch \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "\n",
    "            # Returned values of Dataset Class\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # one hot -> labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "            train_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "            # print statistics\n",
    "            train_loss += loss.item()\n",
    "\n",
    "    train_loss /= (len(train_dataloader.dataset) / batch_size)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    test_loss, test_correct = 0, 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      with tqdm(iter(test_dataloader), desc=\"Test \" + str(epoch), unit=\"batch\") as tepoch:\n",
    "          for batch in tepoch:\n",
    "\n",
    "            images = batch[\"img\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward\n",
    "            outputs = net(images)\n",
    "            test_loss += criterion(outputs, labels)\n",
    "\n",
    "            # one hot -> labels\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "            pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            test_correct += pred.eq(labels).sum().item()\n",
    "\n",
    "    lr_scheduler.step(test_loss)\n",
    "\n",
    "    test_loss /= (len(test_dataloader.dataset) / batch_size)\n",
    "    test_accuracy = 100. * test_correct / len(test_dataloader.dataset)\n",
    "\n",
    "    print(\"[Epoch {}] Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(\n",
    "        epoch + 1, train_loss, test_loss, 100. * train_correct / len(train_dataloader.dataset), test_accuracy\n",
    "    ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_epoch = epoch\n",
    "        # Save best weights\n",
    "        torch.save(net.state_dict(), \"best_model.pt\")\n",
    "\n",
    "\n",
    "print(f\"\\nBEST TEST ACCURACY: {best_accuracy} in epoch  {best_epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlps-Z27HhEAS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
