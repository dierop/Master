{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR & DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import CIFAR10_dataset, CIFAR10_trainer\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as  F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10  train  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  50000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading CIFAR10  test  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 11\n"
     ]
    }
   ],
   "source": [
    "da_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.2, 0.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10_dataset(partition=\"train\", transform=da_train)\n",
    "test_dataset = CIFAR10_dataset(partition=\"test\")\n",
    "\n",
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "\n",
    "batch_size = 150\n",
    "num_workers = multiprocessing.cpu_count()-1\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  # Para ResNet18/34, el factor de expansión es 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample  # Para ajustar dimensiones si es necesario\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Shortcut\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity  # Residual connection\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # Inicial: Convolución, BatchNorm y ReLU\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Bloques residuales\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Clasificación\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def ResNet18(num_classes=1000):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Params:  11181642\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = ResNet18(num_classes)\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=10, min_lr=0.00001)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CIFAR10_trainer(net, train_dataloader, test_dataloader, optimizer,criterion, epochs, lr_scheduler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 334/334 [00:49<00:00,  6.69batch/s]\n",
      "Test 0: 100%|██████████| 67/67 [00:03<00:00, 20.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.422050 - Test Loss: 1.291719 - Train Error: 51.37% - Test Error: 45.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 334/334 [00:51<00:00,  6.43batch/s]\n",
      "Test 1: 100%|██████████| 67/67 [00:03<00:00, 20.21batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.992447 - Test Loss: 1.236338 - Train Error: 35.20% - Test Error: 41.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: 100%|██████████| 334/334 [00:52<00:00,  6.32batch/s]\n",
      "Test 2: 100%|██████████| 67/67 [00:03<00:00, 19.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.741086 - Test Loss: 1.352292 - Train Error: 26.16% - Test Error: 43.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100%|██████████| 334/334 [00:53<00:00,  6.21batch/s]\n",
      "Test 3: 100%|██████████| 67/67 [00:03<00:00, 19.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.558068 - Test Loss: 0.927288 - Train Error: 19.51% - Test Error: 29.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 334/334 [00:54<00:00,  6.11batch/s]\n",
      "Test 4: 100%|██████████| 67/67 [00:03<00:00, 19.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.410135 - Test Loss: 0.937374 - Train Error: 14.32% - Test Error: 29.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 334/334 [00:54<00:00,  6.14batch/s]\n",
      "Test 5: 100%|██████████| 67/67 [00:03<00:00, 19.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.297153 - Test Loss: 1.056058 - Train Error: 10.38% - Test Error: 30.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100%|██████████| 334/334 [00:54<00:00,  6.12batch/s]\n",
      "Test 6: 100%|██████████| 67/67 [00:03<00:00, 19.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.219347 - Test Loss: 0.967086 - Train Error: 7.68% - Test Error: 27.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 334/334 [00:54<00:00,  6.16batch/s]\n",
      "Test 7: 100%|██████████| 67/67 [00:03<00:00, 19.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.163105 - Test Loss: 1.174810 - Train Error: 5.81% - Test Error: 27.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100%|██████████| 334/334 [00:53<00:00,  6.24batch/s]\n",
      "Test 8: 100%|██████████| 67/67 [00:03<00:00, 20.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.117833 - Test Loss: 1.205624 - Train Error: 4.35% - Test Error: 26.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 334/334 [00:53<00:00,  6.25batch/s]\n",
      "Test 9: 100%|██████████| 67/67 [00:03<00:00, 20.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.098515 - Test Loss: 1.153253 - Train Error: 3.45% - Test Error: 25.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 334/334 [00:53<00:00,  6.25batch/s]\n",
      "Test 10: 100%|██████████| 67/67 [00:03<00:00, 20.06batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.069904 - Test Loss: 1.292623 - Train Error: 2.49% - Test Error: 25.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 11: 100%|██████████| 67/67 [00:03<00:00, 19.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.054408 - Test Loss: 1.295288 - Train Error: 1.83% - Test Error: 25.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 12: 100%|██████████| 67/67 [00:03<00:00, 19.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.058608 - Test Loss: 1.374830 - Train Error: 2.05% - Test Error: 26.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 13: 100%|██████████| 67/67 [00:03<00:00, 19.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.040388 - Test Loss: 1.437266 - Train Error: 1.41% - Test Error: 25.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: 100%|██████████| 334/334 [00:54<00:00,  6.09batch/s]\n",
      "Test 14: 100%|██████████| 67/67 [00:03<00:00, 19.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.037965 - Test Loss: 1.346324 - Train Error: 1.25% - Test Error: 24.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 334/334 [00:54<00:00,  6.14batch/s]\n",
      "Test 15: 100%|██████████| 67/67 [00:03<00:00, 19.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.011206 - Test Loss: 1.192790 - Train Error: 0.33% - Test Error: 22.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 334/334 [00:53<00:00,  6.21batch/s]\n",
      "Test 16: 100%|██████████| 67/67 [00:03<00:00, 19.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.002791 - Test Loss: 1.188577 - Train Error: 0.02% - Test Error: 22.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 334/334 [00:53<00:00,  6.21batch/s]\n",
      "Test 17: 100%|██████████| 67/67 [00:03<00:00, 20.30batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.001916 - Test Loss: 1.196991 - Train Error: 0.00% - Test Error: 22.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: 100%|██████████| 334/334 [00:53<00:00,  6.23batch/s]\n",
      "Test 18: 100%|██████████| 67/67 [00:03<00:00, 19.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.001399 - Test Loss: 1.191212 - Train Error: 0.00% - Test Error: 22.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 334/334 [00:53<00:00,  6.20batch/s]\n",
      "Test 19: 100%|██████████| 67/67 [00:03<00:00, 20.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.001372 - Test Loss: 1.206467 - Train Error: 0.01% - Test Error: 22.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: 100%|██████████| 334/334 [00:53<00:00,  6.20batch/s]\n",
      "Test 20: 100%|██████████| 67/67 [00:03<00:00, 20.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 0.001089 - Test Loss: 1.202997 - Train Error: 0.00% - Test Error: 22.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 21: 100%|██████████| 67/67 [00:03<00:00, 18.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 0.000962 - Test Loss: 1.207882 - Train Error: 0.00% - Test Error: 22.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: 100%|██████████| 334/334 [00:54<00:00,  6.12batch/s]\n",
      "Test 22: 100%|██████████| 67/67 [00:03<00:00, 19.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 0.000847 - Test Loss: 1.204585 - Train Error: 0.00% - Test Error: 22.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: 100%|██████████| 334/334 [00:53<00:00,  6.23batch/s]\n",
      "Test 23: 100%|██████████| 67/67 [00:03<00:00, 20.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 0.000812 - Test Loss: 1.216567 - Train Error: 0.00% - Test Error: 22.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 334/334 [00:53<00:00,  6.28batch/s]\n",
      "Test 24: 100%|██████████| 67/67 [00:03<00:00, 20.50batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 0.000678 - Test Loss: 1.218650 - Train Error: 0.00% - Test Error: 22.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: 100%|██████████| 334/334 [00:53<00:00,  6.28batch/s]\n",
      "Test 25: 100%|██████████| 67/67 [00:03<00:00, 20.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Loss: 0.000643 - Test Loss: 1.221352 - Train Error: 0.00% - Test Error: 22.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 334/334 [00:53<00:00,  6.28batch/s]\n",
      "Test 26: 100%|██████████| 67/67 [00:03<00:00, 19.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 0.000622 - Test Loss: 1.225814 - Train Error: 0.00% - Test Error: 22.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 334/334 [00:54<00:00,  6.17batch/s]\n",
      "Test 27: 100%|██████████| 67/67 [00:03<00:00, 19.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Loss: 0.000616 - Test Loss: 1.220212 - Train Error: 0.00% - Test Error: 22.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: 100%|██████████| 334/334 [00:53<00:00,  6.23batch/s]\n",
      "Test 28: 100%|██████████| 67/67 [00:03<00:00, 19.75batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Loss: 0.000617 - Test Loss: 1.222406 - Train Error: 0.00% - Test Error: 22.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 29: 100%|██████████| 67/67 [00:03<00:00, 19.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Loss: 0.000615 - Test Loss: 1.221342 - Train Error: 0.00% - Test Error: 22.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: 100%|██████████| 334/334 [00:53<00:00,  6.22batch/s]\n",
      "Test 30: 100%|██████████| 67/67 [00:03<00:00, 20.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train Loss: 0.000598 - Test Loss: 1.226485 - Train Error: 0.00% - Test Error: 22.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: 100%|██████████| 334/334 [00:54<00:00,  6.15batch/s]\n",
      "Test 31: 100%|██████████| 67/67 [00:03<00:00, 19.35batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 0.000580 - Test Loss: 1.220806 - Train Error: 0.00% - Test Error: 22.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: 100%|██████████| 334/334 [00:54<00:00,  6.14batch/s]\n",
      "Test 32: 100%|██████████| 67/67 [00:03<00:00, 19.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train Loss: 0.000590 - Test Loss: 1.218623 - Train Error: 0.00% - Test Error: 22.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 334/334 [00:54<00:00,  6.17batch/s]\n",
      "Test 33: 100%|██████████| 67/67 [00:03<00:00, 19.92batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train Loss: 0.000587 - Test Loss: 1.226335 - Train Error: 0.00% - Test Error: 22.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: 100%|██████████| 334/334 [00:54<00:00,  6.18batch/s]\n",
      "Test 34: 100%|██████████| 67/67 [00:03<00:00, 19.72batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Train Loss: 0.000589 - Test Loss: 1.227540 - Train Error: 0.00% - Test Error: 22.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35: 100%|██████████| 334/334 [00:53<00:00,  6.21batch/s]\n",
      "Test 35: 100%|██████████| 67/67 [00:03<00:00, 19.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Train Loss: 0.000581 - Test Loss: 1.231277 - Train Error: 0.00% - Test Error: 22.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: 100%|██████████| 334/334 [00:53<00:00,  6.20batch/s]\n",
      "Test 36: 100%|██████████| 67/67 [00:03<00:00, 19.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Train Loss: 0.000557 - Test Loss: 1.227990 - Train Error: 0.00% - Test Error: 22.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37: 100%|██████████| 334/334 [00:53<00:00,  6.19batch/s]\n",
      "Test 37: 100%|██████████| 67/67 [00:03<00:00, 20.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Train Loss: 0.000526 - Test Loss: 1.224400 - Train Error: 0.00% - Test Error: 22.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38: 100%|██████████| 334/334 [00:53<00:00,  6.19batch/s]\n",
      "Test 38: 100%|██████████| 67/67 [00:03<00:00, 20.12batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Train Loss: 0.000568 - Test Loss: 1.229258 - Train Error: 0.00% - Test Error: 22.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39: 100%|██████████| 334/334 [00:53<00:00,  6.19batch/s]\n",
      "Test 39: 100%|██████████| 67/67 [00:03<00:00, 19.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Train Loss: 0.000640 - Test Loss: 1.223103 - Train Error: 0.00% - Test Error: 22.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40: 100%|██████████| 334/334 [00:53<00:00,  6.20batch/s]\n",
      "Test 40: 100%|██████████| 67/67 [00:03<00:00, 19.72batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41] Train Loss: 0.000573 - Test Loss: 1.218765 - Train Error: 0.00% - Test Error: 22.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41: 100%|██████████| 334/334 [00:53<00:00,  6.21batch/s]\n",
      "Test 41: 100%|██████████| 67/67 [00:03<00:00, 19.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42] Train Loss: 0.000575 - Test Loss: 1.226522 - Train Error: 0.00% - Test Error: 22.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42: 100%|██████████| 334/334 [00:53<00:00,  6.19batch/s]\n",
      "Test 42: 100%|██████████| 67/67 [00:03<00:00, 20.01batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43] Train Loss: 0.000562 - Test Loss: 1.225011 - Train Error: 0.00% - Test Error: 22.19%\n",
      "\n",
      "Early Stopping at epoch  42\n",
      "\n",
      "BEST TEST ERROR:  22.02  in epoch  26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlps-Z27HhEAS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
