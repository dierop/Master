{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import CIFAR10_dataset, CIFAR10_trainer\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as  F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import default_collate\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10  train  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  50000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading CIFAR10  test  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 11\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def add_gaussian_noise(img, mean=0, std=0.1):\n",
    "    noise = torch.randn(img.size()) * std + mean\n",
    "    return img + noise\n",
    "\n",
    "# Transformaciones para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    # transforms.RandomGrayscale(p=0.1),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    transforms.Lambda(lambda x: add_gaussian_noise(x, 0, 0.1)),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CIFAR10_dataset(partition=\"train\", transform=train_transforms)\n",
    "test_dataset = CIFAR10_dataset(partition=\"test\")\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "\n",
    "batch_size = 150\n",
    "num_workers = multiprocessing.cpu_count()-1\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "####################################################################\n",
    "# Neural Network Class\n",
    "####################################################################\n",
    "\n",
    "# Define the CNN model\n",
    "# Define ResBlocks to create a CNN\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv_shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.conv_shortcut(x)\n",
    "\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        layers=[ResBlock(3, 32, stride=1)]\n",
    "        channels = [32, 64, 128, 256]\n",
    "        for  c in channels:\n",
    "\n",
    "            layers.append(ResBlock(c, c , stride=1))\n",
    "\n",
    "            layers.append(ResBlock(c , c * 2, stride=2))\n",
    "        layers.append(ResBlock(512, 512, stride=1))\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            *layers\n",
    "            )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input = torch.zeros(1, 3, 32, 32)\n",
    "            output = self.conv_layers(input)\n",
    "            size = output.view(1, -1).shape[1]\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv_shortcut): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Params:  12587018\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = CNN(num_classes)\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "epochs = 200\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.002, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=0.01, steps_per_epoch=len(train_dataloader), epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CIFAR10_trainer(net, train_dataloader, test_dataloader, optimizer,criterion, epochs, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 334/334 [12:32<00:00,  2.25s/batch]\n",
      "Test 0: 100%|██████████| 67/67 [00:25<00:00,  2.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.100268 - Test Loss: 0.934889 - Train Error: 62.24% - Test Error: 50.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 334/334 [12:24<00:00,  2.23s/batch]\n",
      "Test 1: 100%|██████████| 67/67 [00:25<00:00,  2.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.777286 - Test Loss: 0.719255 - Train Error: 41.63% - Test Error: 38.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 334/334 [11:50<00:00,  2.13s/batch]\n",
      "Test 2: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.608509 - Test Loss: 0.627263 - Train Error: 31.81% - Test Error: 32.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100%|██████████| 334/334 [11:53<00:00,  2.14s/batch]\n",
      "Test 3: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.480524 - Test Loss: 0.514085 - Train Error: 24.66% - Test Error: 25.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100%|██████████| 334/334 [11:50<00:00,  2.13s/batch]\n",
      "Test 4: 100%|██████████| 67/67 [00:22<00:00,  2.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.395389 - Test Loss: 0.485256 - Train Error: 20.23% - Test Error: 24.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: 100%|██████████| 334/334 [11:49<00:00,  2.12s/batch]\n",
      "Test 5: 100%|██████████| 67/67 [00:23<00:00,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.328899 - Test Loss: 0.458836 - Train Error: 16.56% - Test Error: 22.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100%|██████████| 334/334 [11:52<00:00,  2.13s/batch]\n",
      "Test 6: 100%|██████████| 67/67 [00:23<00:00,  2.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.271444 - Test Loss: 0.490396 - Train Error: 13.71% - Test Error: 22.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: 100%|██████████| 334/334 [11:52<00:00,  2.13s/batch]\n",
      "Test 7: 100%|██████████| 67/67 [00:23<00:00,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.225628 - Test Loss: 0.479833 - Train Error: 11.52% - Test Error: 21.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100%|██████████| 334/334 [12:23<00:00,  2.22s/batch]\n",
      "Test 8: 100%|██████████| 67/67 [00:24<00:00,  2.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.180153 - Test Loss: 0.528370 - Train Error: 9.03% - Test Error: 22.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 334/334 [12:19<00:00,  2.21s/batch]\n",
      "Test 9: 100%|██████████| 67/67 [00:25<00:00,  2.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.149515 - Test Loss: 0.470059 - Train Error: 7.53% - Test Error: 19.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: 100%|██████████| 334/334 [11:50<00:00,  2.13s/batch]\n",
      "Test 10: 100%|██████████| 67/67 [00:23<00:00,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.123308 - Test Loss: 0.480408 - Train Error: 6.21% - Test Error: 18.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 11: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.100758 - Test Loss: 0.574087 - Train Error: 5.04% - Test Error: 20.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: 100%|██████████| 334/334 [11:50<00:00,  2.13s/batch]\n",
      "Test 12: 100%|██████████| 67/67 [00:23<00:00,  2.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.083258 - Test Loss: 0.527160 - Train Error: 4.12% - Test Error: 18.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: 100%|██████████| 334/334 [11:49<00:00,  2.12s/batch]\n",
      "Test 13: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.072876 - Test Loss: 0.531182 - Train Error: 3.54% - Test Error: 18.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 14: 100%|██████████| 67/67 [00:22<00:00,  2.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.057931 - Test Loss: 0.609134 - Train Error: 2.89% - Test Error: 18.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 15: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.056960 - Test Loss: 0.568437 - Train Error: 2.85% - Test Error: 18.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 16: 100%|██████████| 67/67 [00:23<00:00,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.047167 - Test Loss: 0.605129 - Train Error: 2.40% - Test Error: 18.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: 100%|██████████| 334/334 [11:51<00:00,  2.13s/batch]\n",
      "Test 17: 100%|██████████| 67/67 [00:23<00:00,  2.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.043500 - Test Loss: 0.632386 - Train Error: 2.17% - Test Error: 18.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: 100%|██████████| 334/334 [11:49<00:00,  2.12s/batch]\n",
      "Test 18: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.039203 - Test Loss: 0.607492 - Train Error: 1.98% - Test Error: 18.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 19: 100%|██████████| 67/67 [00:23<00:00,  2.84batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.040518 - Test Loss: 0.636192 - Train Error: 1.99% - Test Error: 18.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: 100%|██████████| 334/334 [11:48<00:00,  2.12s/batch]\n",
      "Test 20: 100%|██████████| 67/67 [00:22<00:00,  2.97batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 0.035157 - Test Loss: 0.659052 - Train Error: 1.67% - Test Error: 18.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: 100%|██████████| 334/334 [11:49<00:00,  2.12s/batch]\n",
      "Test 21: 100%|██████████| 67/67 [00:22<00:00,  2.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 0.033527 - Test Loss: 0.620853 - Train Error: 1.66% - Test Error: 18.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: 100%|██████████| 334/334 [11:50<00:00,  2.13s/batch]\n",
      "Test 22: 100%|██████████| 67/67 [00:23<00:00,  2.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 0.033198 - Test Loss: 0.653464 - Train Error: 1.63% - Test Error: 19.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23:  75%|███████▌  | 251/334 [8:14:07<2:43:23, 118.12s/batch]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Master/RNA/cifar_tests/main.py:95\u001b[0m, in \u001b[0;36mCIFAR10_trainer.train\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m     93\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     94\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m train_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n\u001b[1;32m     98\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlps-Z27HhEAS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
