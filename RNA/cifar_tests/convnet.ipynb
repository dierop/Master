{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR & DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import CIFAR10_dataset, CIFAR10_trainer\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as  F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import default_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR10  train  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  50000 \n",
      " --------------------------------------------------\n",
      "\n",
      "Loading CIFAR10  test  Dataset...\n",
      "Files already downloaded and verified\n",
      "\tTotal Len.:  10000 \n",
      " --------------------------------------------------\n",
      "Num workers 11\n"
     ]
    }
   ],
   "source": [
    "def add_gaussian_noise(img, mean=0, std=0.1):\n",
    "    noise = torch.randn(img.size()) * std + mean\n",
    "    return img + noise\n",
    "\n",
    "# Transformaciones para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
    "    transforms.Lambda(lambda x: add_gaussian_noise(x, 0, 0.1)),\n",
    "])\n",
    "train_dataset = CIFAR10_dataset(partition=\"train\", transform=train_transforms)\n",
    "test_dataset = CIFAR10_dataset(partition=\"test\")\n",
    "\n",
    "# CutMix and MixUp\n",
    "cutmix = v2.CutMix(num_classes=10)\n",
    "mixup = v2.MixUp(num_classes=10)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data = default_collate(batch)  # Asegura el formato (inputs, targets)\n",
    "    inputs, labels= cutmix_or_mixup(data['img'], data['label']) # Aplica CutMix o MixUp\n",
    "    return {\"img\": inputs, \"label\": labels}\n",
    "\n",
    "####################################################################\n",
    "# DataLoader Class\n",
    "####################################################################\n",
    "\n",
    "batch_size = 200\n",
    "num_workers = multiprocessing.cpu_count()-1\n",
    "print(\"Num workers\", num_workers)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 48, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(48)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(48, 96, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(192)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(192, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = self.leaky_relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "Params:  817866\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the network and printing its architecture\n",
    "num_classes = 10\n",
    "net = ConvNet()\n",
    "print(net)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Params: \", count_parameters(net))\n",
    "\n",
    "####################################################################\n",
    "# Training settings\n",
    "####################################################################\n",
    "\n",
    "# Training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=10, min_lr=0.00001)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CIFAR10_trainer(net, train_dataloader, test_dataloader, optimizer,criterion, epochs, lr_scheduler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 250/250 [04:15<00:00,  1.02s/batch]\n",
      "Test 0: 100%|██████████| 50/50 [00:02<00:00, 19.44batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 2.055607 - Test Loss: 1.682266 - Train Error: 74.33% - Test Error: 64.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: 100%|██████████| 250/250 [04:12<00:00,  1.01s/batch]\n",
      "Test 1: 100%|██████████| 50/50 [00:02<00:00, 19.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 1.880430 - Test Loss: 1.699104 - Train Error: 63.35% - Test Error: 64.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: 100%|██████████| 250/250 [04:12<00:00,  1.01s/batch]\n",
      "Test 2: 100%|██████████| 50/50 [00:02<00:00, 19.05batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 1.776317 - Test Loss: 1.419347 - Train Error: 57.11% - Test Error: 49.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: 100%|██████████| 250/250 [04:12<00:00,  1.01s/batch]\n",
      "Test 3: 100%|██████████| 50/50 [00:02<00:00, 19.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 1.733997 - Test Loss: 1.326844 - Train Error: 54.12% - Test Error: 45.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: 100%|██████████| 250/250 [04:11<00:00,  1.01s/batch]\n",
      "Test 4: 100%|██████████| 50/50 [00:02<00:00, 19.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 1.692569 - Test Loss: 1.340934 - Train Error: 52.11% - Test Error: 49.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: 100%|██████████| 250/250 [04:11<00:00,  1.00s/batch]\n",
      "Test 5: 100%|██████████| 50/50 [00:02<00:00, 19.77batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 1.658057 - Test Loss: 1.362278 - Train Error: 49.88% - Test Error: 48.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: 100%|██████████| 250/250 [03:58<00:00,  1.05batch/s]\n",
      "Test 6: 100%|██████████| 50/50 [00:02<00:00, 19.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 1.637960 - Test Loss: 1.282512 - Train Error: 48.84% - Test Error: 44.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 250/250 [03:58<00:00,  1.05batch/s]\n",
      "Test 7: 100%|██████████| 50/50 [00:02<00:00, 19.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 1.600741 - Test Loss: 1.098479 - Train Error: 46.99% - Test Error: 38.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: 100%|██████████| 250/250 [03:59<00:00,  1.04batch/s]\n",
      "Test 8: 100%|██████████| 50/50 [00:02<00:00, 19.41batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 1.578000 - Test Loss: 1.057486 - Train Error: 45.58% - Test Error: 36.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 250/250 [03:58<00:00,  1.05batch/s]\n",
      "Test 9: 100%|██████████| 50/50 [00:02<00:00, 19.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 1.546593 - Test Loss: 1.164440 - Train Error: 43.60% - Test Error: 43.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: 100%|██████████| 250/250 [04:05<00:00,  1.02batch/s]\n",
      "Test 10: 100%|██████████| 50/50 [00:02<00:00, 19.37batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 1.554080 - Test Loss: 1.225213 - Train Error: 43.47% - Test Error: 42.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11: 100%|██████████| 250/250 [04:10<00:00,  1.00s/batch]\n",
      "Test 11: 100%|██████████| 50/50 [00:02<00:00, 18.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 1.504563 - Test Loss: 1.186360 - Train Error: 42.53% - Test Error: 41.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: 100%|██████████| 250/250 [04:09<00:00,  1.00batch/s]\n",
      "Test 12: 100%|██████████| 50/50 [00:02<00:00, 19.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 1.539617 - Test Loss: 1.137076 - Train Error: 43.14% - Test Error: 39.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: 100%|██████████| 250/250 [04:08<00:00,  1.01batch/s]\n",
      "Test 13: 100%|██████████| 50/50 [00:02<00:00, 19.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 1.494698 - Test Loss: 0.957423 - Train Error: 41.59% - Test Error: 32.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14: 100%|██████████| 250/250 [04:10<00:00,  1.00s/batch]\n",
      "Test 14: 100%|██████████| 50/50 [00:02<00:00, 19.44batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 1.516490 - Test Loss: 1.212668 - Train Error: 41.17% - Test Error: 42.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: 100%|██████████| 250/250 [04:10<00:00,  1.00s/batch]\n",
      "Test 15: 100%|██████████| 50/50 [00:02<00:00, 19.34batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 1.494042 - Test Loss: 1.083990 - Train Error: 40.41% - Test Error: 38.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: 100%|██████████| 250/250 [04:04<00:00,  1.02batch/s]\n",
      "Test 16: 100%|██████████| 50/50 [00:02<00:00, 19.41batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 1.500807 - Test Loss: 1.029570 - Train Error: 40.89% - Test Error: 34.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: 100%|██████████| 250/250 [03:57<00:00,  1.05batch/s]\n",
      "Test 17: 100%|██████████| 50/50 [00:02<00:00, 19.80batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 1.468866 - Test Loss: 0.919396 - Train Error: 38.96% - Test Error: 30.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: 100%|██████████| 250/250 [03:58<00:00,  1.05batch/s]\n",
      "Test 18: 100%|██████████| 50/50 [00:02<00:00, 19.87batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 1.449669 - Test Loss: 0.926166 - Train Error: 38.06% - Test Error: 30.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 250/250 [03:57<00:00,  1.05batch/s]\n",
      "Test 19: 100%|██████████| 50/50 [00:02<00:00, 19.56batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 1.455356 - Test Loss: 0.902225 - Train Error: 38.50% - Test Error: 28.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: 100%|██████████| 250/250 [04:09<00:00,  1.00batch/s]\n",
      "Test 20: 100%|██████████| 50/50 [00:02<00:00, 19.06batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 1.454664 - Test Loss: 1.060336 - Train Error: 37.70% - Test Error: 36.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: 100%|██████████| 250/250 [04:11<00:00,  1.01s/batch]\n",
      "Test 21: 100%|██████████| 50/50 [00:02<00:00, 19.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 1.444730 - Test Loss: 0.908588 - Train Error: 37.87% - Test Error: 31.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22: 100%|██████████| 250/250 [04:06<00:00,  1.01batch/s]\n",
      "Test 22: 100%|██████████| 50/50 [00:02<00:00, 18.81batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 1.420742 - Test Loss: 0.872938 - Train Error: 36.60% - Test Error: 28.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: 100%|██████████| 250/250 [04:08<00:00,  1.01batch/s]\n",
      "Test 23: 100%|██████████| 50/50 [00:02<00:00, 19.02batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 1.402776 - Test Loss: 0.823862 - Train Error: 36.06% - Test Error: 27.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24: 100%|██████████| 250/250 [04:06<00:00,  1.02batch/s]\n",
      "Test 24: 100%|██████████| 50/50 [00:02<00:00, 19.13batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 1.443039 - Test Loss: 0.960961 - Train Error: 38.50% - Test Error: 32.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25: 100%|██████████| 250/250 [04:07<00:00,  1.01batch/s]\n",
      "Test 25: 100%|██████████| 50/50 [00:02<00:00, 19.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Loss: 1.408816 - Test Loss: 0.793695 - Train Error: 36.59% - Test Error: 26.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26: 100%|██████████| 250/250 [04:01<00:00,  1.04batch/s]\n",
      "Test 26: 100%|██████████| 50/50 [00:02<00:00, 19.31batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 1.422118 - Test Loss: 0.941739 - Train Error: 35.25% - Test Error: 31.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27: 100%|██████████| 250/250 [03:56<00:00,  1.06batch/s]\n",
      "Test 27: 100%|██████████| 50/50 [00:02<00:00, 19.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Loss: 1.427887 - Test Loss: 0.836165 - Train Error: 36.97% - Test Error: 26.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28: 100%|██████████| 250/250 [03:56<00:00,  1.06batch/s]\n",
      "Test 28: 100%|██████████| 50/50 [00:02<00:00, 19.87batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Loss: 1.383569 - Test Loss: 0.809632 - Train Error: 35.12% - Test Error: 27.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29: 100%|██████████| 250/250 [03:56<00:00,  1.06batch/s]\n",
      "Test 29: 100%|██████████| 50/50 [00:02<00:00, 19.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Loss: 1.403354 - Test Loss: 0.816733 - Train Error: 36.06% - Test Error: 25.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: 100%|██████████| 250/250 [03:57<00:00,  1.05batch/s]\n",
      "Test 30: 100%|██████████| 50/50 [00:02<00:00, 19.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train Loss: 1.397169 - Test Loss: 0.775980 - Train Error: 35.55% - Test Error: 25.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31: 100%|██████████| 250/250 [03:56<00:00,  1.06batch/s]\n",
      "Test 31: 100%|██████████| 50/50 [00:02<00:00, 19.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 1.360214 - Test Loss: 0.849262 - Train Error: 34.22% - Test Error: 28.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32: 100%|██████████| 250/250 [03:55<00:00,  1.06batch/s]\n",
      "Test 32: 100%|██████████| 50/50 [00:02<00:00, 19.45batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train Loss: 1.347633 - Test Loss: 0.719727 - Train Error: 33.06% - Test Error: 21.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33: 100%|██████████| 250/250 [03:55<00:00,  1.06batch/s]\n",
      "Test 33: 100%|██████████| 50/50 [00:02<00:00, 19.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train Loss: 1.384001 - Test Loss: 0.820249 - Train Error: 33.61% - Test Error: 25.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34:   9%|▉         | 23/250 [00:22<03:44,  1.01batch/s]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlps-Z27HhEAS-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
